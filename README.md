# ğŸ§­ Agent Travel Assistant

### âœ¨ Overview
**Agent Travel Assistant** is an intelligent AI application that helps users automatically **generate personalized travel itineraries** from natural language input.  
The system includes:
- ğŸ§  **Backend (FastAPI)** â€” Handles user queries and interacts with LLMs (OpenAI or Ollama).
- ğŸŒ **Frontend (React + Vite)** â€” Simple and interactive user interface.
- ğŸ³ **Docker (optional)** â€” For easy and consistent deployment.

---

## ğŸ“ Project Structure
```
AgentTravelAssistant/
â”‚
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ routes/          # API routes (chat, LLM handler, etc.)
â”‚   â”‚   â”œâ”€â”€ core/            # Configurations & utilities
â”‚   â”‚   â”œâ”€â”€ agents/          # LLM agent logic
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI entrypoint
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ frontend/                # React + Vite frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ docker-compose.yml       # (Optional) Docker setup
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation & Setup

### ğŸ”¹ Requirements
- Python **3.10+**
- Node.js **18+**
- (Optional) Docker & Docker Compose

---

## ğŸ§  1. Backend Setup (FastAPI)

```bash
cd backend
python3 -m venv venv
source venv/bin/activate   # macOS / Linux
venv\Scripts\activate      # Windows

pip install -r requirements.txt
```

Create a `.env` file based on the example:
```bash
cp .env.example .env
```

Then edit `.env`:
```bash
# BACKEND
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini
LLM_BACKEND=openai           # or ollama
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# FRONTEND
VITE_API_BASE=http://localhost:8000
```

Run the server:
```bash
uvicorn app.main:app --reload
```

Backend runs at ğŸ‘‰ **http://localhost:8000**

---

## ğŸ’» 2. Frontend Setup (React + Vite)

```bash
cd frontend
npm install
```

Create `.env`:
```bash
cp .env.example .env
```

Edit it:
```bash
VITE_API_BASE=http://localhost:8000
```

Run the development server:
```bash
npm run dev
```

Frontend runs at ğŸ‘‰ **http://localhost:5173**

---

## ğŸ³ 3. (Optional) Docker Setup

Run the entire stack via Docker Compose:
```bash
docker compose up --build
```

---

## ğŸ§© 4. LLM Integration
Option 1: **OpenAI API**
- Set your `OPENAI_API_KEY`
- Set `LLM_BACKEND=openai`

Option 2: **Ollama (local model)**
- Install [Ollama](https://ollama.ai)
- Pull model:
  ```bash
  ollama pull llama3.2
  ```
- Set:
  ```bash
  LLM_BACKEND=ollama
  OLLAMA_URL=http://localhost:11434
  ```

---

## ğŸš€ Run the App
Open your browser and go to:
```
http://localhost:5173
```
Example query:
> â€œPlan a 3-day trip to Da Nangâ€

The AI will automatically generate a travel itinerary for you. ğŸŒ´